# -*- coding: utf-8 -*-
"""XL_splice.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QDLrbKEEgZamzCK7FUaFjHTPGedUjyX7
"""
import torch
from transformers import TransfoXLTokenizer, TransfoXLModel, TransfoXLConfig
from torch.nn import CrossEntropyLoss
import numpy as np

class Model(torch.nn.Module):
  def __init__(self):
    super(Model, self).__init__()
    self.config = TransfoXLConfig(vocab_size_or_config_json_file=len(vocab)+267735)
    self.model = TransfoXLModel(self.config)
    self.tokenizer = TransfoXLTokenizer.from_pretrained('transfo-xl-wt103')
    self.out_layer = torch.nn.Linear(self.model.d_model, 2)
  def forward(self, input_ids, mems=None):
    hidden_states, mems = self.model(input_ids, mems)
    preds = self.out_layer(hidden_states).squeeze(0)
    return preds, mems
def main():
	batch_size = 1
	window_size = 1012
	vocab, genes, labels, max_len = get_data("/content/drive/My Drive/all_samples_6-mer.txt")
	model = Model()
	model.tokenizer.add_tokens(list(vocab))
	optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
	class_weights = torch.tensor(np.array([1.0, 100.0])).float()
	loss = CrossEntropyLoss(weight=class_weights)
	total_loss = 0
	for i in range(0, len(genes)):
		mems = None
		print("running on gene: " + str(i))
		gene_loss = 0
		for w in range(0, len(genes[i]), window_size):
			toks = np.array(model.tokenizer.convert_tokens_to_ids(genes[i][w:w+window_size]))
			input_ids = torch.tensor(toks).unsqueeze(0)
			gene_labels = torch.tensor(np.array(labels[i][w:w+window_size])).long()
			predictions, mems = model(input_ids, mems)
			optimizer.zero_grad()
			l = loss(predictions, gene_labels)
			gene_loss += l.item()
			l.backward()
			optimizer.step()
		total_loss += gene_loss
		if i > 0 and i % 10 == 0:
			print("Epoch: " + str(i) + " loss: " + str(total_loss / 10))
			total_loss = 0
if __name__ == '__main__':
	main()

