{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "XL_splice.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pyiw7HykT7Ey",
        "colab_type": "code",
        "outputId": "eb633e32-7e91-4e03-b580-395b842af998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        }
      },
      "source": [
        "!pip3 install transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/f9/51824e40f0a23a49eab4fcaa45c1c797cbf9761adedd0b558dab7c958b34/transformers-2.1.1-py3-none-any.whl (311kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Collecting regex\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/8e/cbf2295643d7265e7883326fb4654e643bfc93b3a8a8274d8010a39d8804/regex-2019.11.1-cp36-cp36m-manylinux1_x86_64.whl (643kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 46.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.18)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 49.9MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 38.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.9.11)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.18 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.18)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.0)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.18->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.18->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp36-none-any.whl size=883999 sha256=6a05280885affd3fc8a56d87bb91c4386f53f51f78b4eb8949570e284c527735\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: regex, sentencepiece, sacremoses, transformers\n",
            "Successfully installed regex-2019.11.1 sacremoses-0.0.35 sentencepiece-0.1.83 transformers-2.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0HfppoIUVGP",
        "colab_type": "code",
        "outputId": "4c36b577-ef9f-45a0-f6b4-7b23f464a686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M28FDg5jTEwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def get_data(filepath):\n",
        "\tvocab = set()\n",
        "\tgenes = []\n",
        "\tlabels = []\n",
        "\tmax_len = 0\n",
        "\tcount = 0\n",
        "\twith open(filepath, 'r') as f:\n",
        "\t\tl = f.readline()\n",
        "\t\tl = f.readline()\n",
        "\t\twhile l != None:\n",
        "\t\t\tinside_bracks = re.findall(r'\\[(.*?)\\]',l)\n",
        "\t\t\tif len(inside_bracks) < 2:\n",
        "\t\t\t\tbreak\n",
        "\t\t\tif count == 300:\n",
        "\t\t\t\tbreak\n",
        "\t\t\tmers = inside_bracks[0].split(\", \")\n",
        "\t\t\tmers = [mer[1:-1] for mer in mers]\n",
        "\t\t\tif len(mers) > max_len:\n",
        "\t\t\t\tmax_len = len(mers)\n",
        "\t\t\tgenes.append(mers)\n",
        "\t\t\tgene_labels = inside_bracks[1].split(\", \")\n",
        "\t\t\tgene_labels = list(map(float, gene_labels)) \n",
        "\t\t\tlabels.append(gene_labels)\n",
        "\t\t\tvocab.update(mers)\n",
        "\t\t\tl = f.readline()\n",
        "\t\t\tcount += 1\n",
        "\treturn vocab, genes, labels, max_len\n",
        "\n",
        "def pad(genes, max_len):\n",
        "\tatten_masks = []\n",
        "\tfor i in range(len(genes)):\n",
        "\t\tlength = len(genes[i])\n",
        "\t\tdiff = max_len - length\n",
        "\t\tgenes[i].extend(['[PAD]' for i in range(diff)])\n",
        "\t\tmask = [1 for j in range(length)]\n",
        "\t\tmask.extend([0 for j in range(diff)])\n",
        "\t\tatten_masks.append(np.array(mask))\n",
        "\treturn genes, np.array(atten_masks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-N6D4RkVGzI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "629f7780-85ec-4f1a-f309-527ec5abd1ee"
      },
      "source": [
        "import torch\n",
        "from transformers import TransfoXLTokenizer, TransfoXLModel, TransfoXLConfig\n",
        "class Model(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.config = TransfoXLConfig(vocab_size_or_config_json_file=len(vocab)+267735, n_heads=9, n_layers=8)\n",
        "    self.model = TransfoXLModel(self.config)\n",
        "    self.tokenizer = TransfoXLTokenizer.from_pretrained('transfo-xl-wt103')\n",
        "    self.out_layer = torch.nn.Linear(self.model.d_model, 2)\n",
        "  def forward(self, input_ids, mems=None):\n",
        "    hidden_states, mems = self.model(input_ids, mems)\n",
        "    preds = self.out_layer(hidden_states).squeeze(0)\n",
        "    return preds, mems"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6f5kjRj2eDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byc0Ir-US6e3",
        "colab_type": "code",
        "outputId": "50613b89-5113-4574-d2b8-95579a2cdea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from torch.nn import CrossEntropyLoss\n",
        "import numpy as np\n",
        "batch_size = 1\n",
        "window_size = 1012\n",
        "vocab, genes, labels, max_len = get_data(\"/content/drive/My Drive/attentive_splice/all_samples_6-mer.txt\")\n",
        "#genes, atten_masks = pad(genes, max_len)\n",
        "model = Model()\n",
        "model.to(device)\n",
        "model.tokenizer.add_tokens(list(vocab))\n",
        "#model.load_state_dict(torch.load(\"\")) Camillo, Zach: Add the path to your .pt file if you want to load weights from previous run\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "class_weights = torch.tensor(np.array([1.0, 100.0])).float().cuda()\n",
        "loss = CrossEntropyLoss(weight=class_weights)\n",
        "total_loss = 0\n",
        "model.train()\n",
        "for i in range(0, len(genes)):\n",
        "\tmems = None\n",
        "\tprint(\"running on gene: \" + str(i))\n",
        "\tgene_loss = 0\n",
        "\tfor w in range(0, len(genes[i]), window_size):\n",
        "\t\ttoks = np.array(model.tokenizer.convert_tokens_to_ids(genes[i][w:w+window_size]))\n",
        "\t\tinput_ids = torch.tensor(toks).unsqueeze(0).cuda()\n",
        "\t\tgene_labels = torch.tensor(np.array(labels[i][w:w+window_size])).long().cuda()\n",
        "\t\tpredictions, mems = model(input_ids, mems)\n",
        "\t\toptimizer.zero_grad()\n",
        "\t\tl = loss(predictions, gene_labels)\n",
        "\t\tgene_loss += l.item()\n",
        "\t\tl.backward()\n",
        "\t\toptimizer.step()\n",
        "\ttotal_loss += gene_loss\n",
        "\tif i > 0 and i % 100 == 0:\n",
        "\t\tprint(\"Epoch: \" + str(i) + \" loss: \" + str(total_loss / 100))\n",
        "\t\ttotal_loss = 0\n",
        "\tif i > 0 and i % 500 == 0:\n",
        "\t\tpath = \"/content/drive/My Drive/attentive_splice/\" + str(i) + \".pt\"\n",
        "\t\ttorch.save(model.state_dict(), path)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 9143613/9143613 [00:00<00:00, 31827530.88B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "running on gene: 0\n",
            "running on gene: 1\n",
            "running on gene: 2\n",
            "running on gene: 3\n",
            "running on gene: 4\n",
            "running on gene: 5\n",
            "running on gene: 6\n",
            "running on gene: 7\n",
            "running on gene: 8\n",
            "running on gene: 9\n",
            "running on gene: 10\n",
            "running on gene: 11\n",
            "running on gene: 12\n",
            "running on gene: 13\n",
            "running on gene: 14\n",
            "running on gene: 15\n",
            "running on gene: 16\n",
            "running on gene: 17\n",
            "running on gene: 18\n",
            "running on gene: 19\n",
            "running on gene: 20\n",
            "running on gene: 21\n",
            "running on gene: 22\n",
            "running on gene: 23\n",
            "running on gene: 24\n",
            "running on gene: 25\n",
            "running on gene: 26\n",
            "running on gene: 27\n",
            "running on gene: 28\n",
            "running on gene: 29\n",
            "running on gene: 30\n",
            "running on gene: 31\n",
            "running on gene: 32\n",
            "running on gene: 33\n",
            "running on gene: 34\n",
            "running on gene: 35\n",
            "running on gene: 36\n",
            "running on gene: 37\n",
            "running on gene: 38\n",
            "running on gene: 39\n",
            "running on gene: 40\n",
            "running on gene: 41\n",
            "running on gene: 42\n",
            "running on gene: 43\n",
            "running on gene: 44\n",
            "running on gene: 45\n",
            "running on gene: 46\n",
            "running on gene: 47\n",
            "running on gene: 48\n",
            "running on gene: 49\n",
            "running on gene: 50\n",
            "running on gene: 51\n",
            "running on gene: 52\n",
            "running on gene: 53\n",
            "running on gene: 54\n",
            "running on gene: 55\n",
            "running on gene: 56\n",
            "running on gene: 57\n",
            "running on gene: 58\n",
            "running on gene: 59\n",
            "running on gene: 60\n",
            "running on gene: 61\n",
            "running on gene: 62\n",
            "running on gene: 63\n",
            "running on gene: 64\n",
            "running on gene: 65\n",
            "running on gene: 66\n",
            "running on gene: 67\n",
            "running on gene: 68\n",
            "running on gene: 69\n",
            "running on gene: 70\n",
            "running on gene: 71\n",
            "running on gene: 72\n",
            "running on gene: 73\n",
            "running on gene: 74\n",
            "running on gene: 75\n",
            "running on gene: 76\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKUtG7QZYLIW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}